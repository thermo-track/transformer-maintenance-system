{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62028142",
   "metadata": {},
   "source": [
    "# Load Dependencies\n",
    "This notebook drives the feedback fine-tuning pipeline end to end so we can verify the service works with the sample payload in `tms-model-finetune/test.json`. Run each section sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec83fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies for the fine-tuning workflow\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "import config\n",
    "from dataset import build_dataset\n",
    "from schemas import FineTuneRequest\n",
    "from trainer import run_finetune\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d35146",
   "metadata": {},
   "source": [
    "# Inspect Pipeline Configuration\n",
    "Load and inspect the feedback payload, fixing minor formatting issues so we can validate the detections before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556fb0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [{'detections': [{'box': {'x_max': 250,\n",
      "                                     'x_min': 120,\n",
      "                                     'y_max': 200,\n",
      "                                     'y_min': 80},\n",
      "                             'class_id': 3},\n",
      "                            {'box': {'x_max': 400,\n",
      "                                     'x_min': 300,\n",
      "                                     'y_max': 280,\n",
      "                                     'y_min': 150},\n",
      "                             'class_id': 1}],\n",
      "             'image_url': 'https://res.cloudinary.com/dxqmzslkb/image/upload/v1761047784/transformers/baseline/de72eb41-12c3-43a4-9031-c2911cb986aa/baseline_de72eb41-12c3-43a4-9031-c2911cb986aa_rainy_1761047782394.jpg'}]}\n",
      "Loaded 1 image entries from test.json\n"
     ]
    }
   ],
   "source": [
    "# Load and sanitize the sample JSON payload\n",
    "payload_path = Path(\"test.json\")\n",
    "raw_text = payload_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Remove trailing commas that make the JSON invalid\n",
    "sanitized_text = re.sub(r\",(?=\\s*[}\\]])\", \"\", raw_text)\n",
    "payload_dict = json.loads(sanitized_text)\n",
    "\n",
    "pprint.pprint(payload_dict)\n",
    "print(f\"Loaded {len(payload_dict['images'])} image entries from {payload_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af6950",
   "metadata": {},
   "source": [
    "# Resolve Data Sources\n",
    "Confirm the referenced imagery is reachable and capture basic metadata so we can troubleshoot download failures early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab5dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: https://res.cloudinary.com/dxqmzslkb/image/upload/v1761047784/transformers/baseline/de72eb41-12c3-43a4-9031-c2911cb986aa/baseline_de72eb41-12c3-43a4-9031-c2911cb986aa_rainy_1761047782394.jpg (status=200, size=193420)\n"
     ]
    }
   ],
   "source": [
    "# Probe each image URL to ensure it is reachable\n",
    "for entry in payload_dict[\"images\"]:\n",
    "    url = entry[\"image_url\"]\n",
    "    try:\n",
    "        response = requests.head(url, timeout=15)\n",
    "        if response.status_code >= 400:\n",
    "            response = requests.get(url, stream=True, timeout=15)\n",
    "        size = response.headers.get(\"Content-Length\", \"unknown\")\n",
    "        print(f\"OK: {url} (status={response.status_code}, size={size})\")\n",
    "    except requests.RequestException as error:\n",
    "        print(f\"FAILED: {url} ({error})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9858e",
   "metadata": {},
   "source": [
    "# Instantiate Pipeline Components\n",
    "Build the `FineTuneRequest` object that mirrors the payload while overriding hyperparameters for a quick integration test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492312a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneRequest(images=[FeedbackImage(image_url=HttpUrl('https://res.cloudinary.com/dxqmzslkb/image/upload/v1761047784/transformers/baseline/de72eb41-12c3-43a4-9031-c2911cb986aa/baseline_de72eb41-12c3-43a4-9031-c2911cb986aa_rainy_1761047782394.jpg', ), detections=[Detection(box=BoundingBox(x_min=120.0, y_min=80.0, x_max=250.0, y_max=200.0), class_id=3), Detection(box=BoundingBox(x_min=300.0, y_min=150.0, x_max=400.0, y_max=280.0), class_id=1)])], train_replay=0, epochs=2, batch_size=4, image_size=None, learning_rate=0.0001, weight_decay=0.0001, momentum=None, freeze=10, seed=None, device=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pydantic request object with lightweight hyperparameters for testing\n",
    "request_payload = FineTuneRequest(\n",
    "    images=payload_dict[\"images\"],\n",
    "    train_replay=0,\n",
    "    epochs=2,\n",
    "    batch_size=4,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    freeze=10,\n",
    ")\n",
    "request_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e41a2",
   "metadata": {},
   "source": [
    "# Execute Training Pipeline\n",
    "Run the fine-tuning job against the temporary dataset that mixes feedback images with the configured replay samples (disabled here for speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d11b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 23:58:08,321 | INFO | Starting fine-tune run finetune_20251021T182808Z\n",
      "2025-10-21 23:58:08,322 | INFO | Feedback images: 1\n",
      "2025-10-21 23:58:08,323 | INFO | Base weights: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-fault-detection-model\\weights\\best.pt\n",
      "2025-10-21 23:58:08,324 | INFO | Falling back to CPU\n",
      "2025-10-21 23:58:08,322 | INFO | Feedback images: 1\n",
      "2025-10-21 23:58:08,323 | INFO | Base weights: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-fault-detection-model\\weights\\best.pt\n",
      "2025-10-21 23:58:08,324 | INFO | Falling back to CPU\n",
      "2025-10-21 23:58:09,398 | INFO | Registered feedback sample feedback_000_baseline_de72eb41-12c3-43a4-9031-c2911cb986aa_rainy_1761047782394_b6eb874199.jpg with 2 detections\n",
      "2025-10-21 23:58:09,398 | INFO | Registered feedback sample feedback_000_baseline_de72eb41-12c3-43a4-9031-c2911cb986aa_rainy_1761047782394_b6eb874199.jpg with 2 detections\n",
      "2025-10-21 23:58:09,777 | INFO | Dataset ready at D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z (feedback=1, replay=0)\n",
      "2025-10-21 23:58:09,777 | INFO | Dataset ready at D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z (feedback=1, replay=0)\n",
      "Ultralytics 8.3.218  Python-3.11.8 torch-2.9.0+cpu CPU (11th Gen Intel Core i5-1135G7 @ 2.40GHz)\n",
      "Ultralytics 8.3.218  Python-3.11.8 torch-2.9.0+cpu CPU (11th Gen Intel Core i5-1135G7 @ 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\\dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-fault-detection-model\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=finetune_20251021T182808Z, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=1337, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\\dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-fault-detection-model\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=finetune_20251021T182808Z, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=1337, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    821343  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
      " 23        [16, 19, 22]  1    821343  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,429,727 parameters, 9,429,711 gradients, 21.6 GFLOPs\n",
      "\n",
      "YOLO11s summary: 181 layers, 9,429,727 parameters, 9,429,711 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 685.10.0 MB/s, size: 188.2 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 685.10.0 MB/s, size: 188.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\\labels\\train... 1 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1/1 10.5it/s 0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\\labels\\train.cache\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\\labels\\train... 1 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1/1 10.5it/s 0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 14.313.3 ms, read: 4.03.5 MB/s, size: 146.4 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 14.313.3 ms, read: 4.03.5 MB/s, size: 146.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\valid\\labels... 21 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 21/21 173.5it/s 0.1s.1s\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\valid\\labels... 21 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 21/21 173.5it/s 0.1s.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\valid\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\valid\\labels.cache\n",
      "Plotting labels to D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\labels.jpg... \n",
      "Plotting labels to D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mD:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mD:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/2         0G      4.206      11.99      2.926          4        640: 100% ━━━━━━━━━━━━ 1/1 0.2it/s 4.7s\n",
      "\u001b[K        1/2         0G      4.206      11.99      2.926          4        640: 100% ━━━━━━━━━━━━ 1/1 0.2it/s 4.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.3it/s 11.9s.2ss\n",
      "\n",
      "                   all         21         34      0.354      0.385      0.348      0.211\n",
      "                   all         21         34      0.354      0.385      0.348      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/2         0G   0.001633       8.07  0.0006753          4        640: 100% ━━━━━━━━━━━━ 1/1 0.4it/s 2.3s\n",
      "\u001b[K        2/2         0G   0.001633       8.07  0.0006753          4        640: 100% ━━━━━━━━━━━━ 1/1 0.4it/s 2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.4it/s 7.6s5.3ss\n",
      "                   all         21         34      0.356      0.387      0.344      0.207\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.4it/s 7.6s\n",
      "                   all         21         34      0.356      0.387      0.344      0.207\n",
      "\n",
      "2 epochs completed in 0.008 hours.\n",
      "\n",
      "2 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\weights\\best.pt, 19.2MB\n",
      "Optimizer stripped from D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\weights\\best.pt...\n",
      "Ultralytics 8.3.218  Python-3.11.8 torch-2.9.0+cpu CPU (11th Gen Intel Core i5-1135G7 @ 2.40GHz)\n",
      "\n",
      "Validating D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\\weights\\best.pt...\n",
      "Ultralytics 8.3.218  Python-3.11.8 torch-2.9.0+cpu CPU (11th Gen Intel Core i5-1135G7 @ 2.40GHz)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.5it/s 6.4s4.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.5it/s 6.4s\n",
      "                   all         21         34      0.354      0.385      0.348      0.211\n",
      "   Loose Joint -Faulty         11         13      0.358      0.602      0.494      0.321\n",
      "Loose Joint -Potential          3          5      0.391        0.4      0.302      0.124\n",
      "Point Overload - Faulty          1          1          0          0          0          0\n",
      "                normal         11         15      0.668      0.536      0.597        0.4\n",
      "Speed: 5.4ms preprocess, 268.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\u001b[0m\n",
      "                   all         21         34      0.354      0.385      0.348      0.211\n",
      "   Loose Joint -Faulty         11         13      0.358      0.602      0.494      0.321\n",
      "Loose Joint -Potential          3          5      0.391        0.4      0.302      0.124\n",
      "Point Overload - Faulty          1          1          0          0          0          0\n",
      "                normal         11         15      0.668      0.536      0.597        0.4\n",
      "Speed: 5.4ms preprocess, 268.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\finetune_20251021T182808Z\u001b[0m\n",
      "2025-10-21 23:59:26,643 | INFO | Exported fine-tuned weights to D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\finetune_weight\\best_finetune.pt\n",
      "2025-10-21 23:59:26,643 | INFO | Exported fine-tuned weights to D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\finetune_weight\\best_finetune.pt\n",
      "Ultralytics 8.3.218  Python-3.11.8 torch-2.9.0+cpu CPU (11th Gen Intel Core i5-1135G7 @ 2.40GHz)\n",
      "Ultralytics 8.3.218  Python-3.11.8 torch-2.9.0+cpu CPU (11th Gen Intel Core i5-1135G7 @ 2.40GHz)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.85.8 ms, read: 0.90.7 MB/s, size: 21.0 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.85.8 ms, read: 0.90.7 MB/s, size: 21.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\test\\labels... 10 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10/10 89.2it/s 0.1s1s\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\test\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\Annotated_dataset\\test\\labels.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.8it/s 3.9s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 0.8it/s 3.9s\n",
      "                   all         10         16      0.693      0.426      0.509      0.267\n",
      "   Loose Joint -Faulty          7          9      0.685      0.778      0.804      0.443\n",
      "Loose Joint -Potential          4          5          1          0      0.274     0.0815\n",
      "                normal          2          2      0.394        0.5      0.448      0.276\n",
      "Speed: 5.0ms preprocess, 359.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\detect\\val\u001b[0m\n",
      "2025-10-21 23:59:33,831 | INFO | Validation metrics: {\"metrics/precision(B)\": 0.6930394145729896, \"metrics/recall(B)\": 0.4259259259259259, \"metrics/mAP50(B)\": 0.5087361111111111, \"metrics/mAP50-95(B)\": 0.26677821340388, \"fitness\": 0.26677821340388}\n",
      "2025-10-21 23:59:33,831 | INFO | Run summary written to D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\finetune_weight\\last_metrics.json\n",
      "2025-10-21 23:59:33,831 | INFO | Cleaned up temporary dataset at D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\n",
      "                   all         10         16      0.693      0.426      0.509      0.267\n",
      "   Loose Joint -Faulty          7          9      0.685      0.778      0.804      0.443\n",
      "Loose Joint -Potential          4          5          1          0      0.274     0.0815\n",
      "                normal          2          2      0.394        0.5      0.448      0.276\n",
      "Speed: 5.0ms preprocess, 359.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\runs\\detect\\val\u001b[0m\n",
      "2025-10-21 23:59:33,831 | INFO | Validation metrics: {\"metrics/precision(B)\": 0.6930394145729896, \"metrics/recall(B)\": 0.4259259259259259, \"metrics/mAP50(B)\": 0.5087361111111111, \"metrics/mAP50-95(B)\": 0.26677821340388, \"fitness\": 0.26677821340388}\n",
      "2025-10-21 23:59:33,831 | INFO | Run summary written to D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\finetune_weight\\last_metrics.json\n",
      "2025-10-21 23:59:33,831 | INFO | Cleaned up temporary dataset at D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\workdir\\finetune_20251021T182808Z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingSummary(run_id='finetune_20251021T182808Z', weights_path=WindowsPath('D:/7th_sem/Software Design Project/transformer-maintenance-system/tms-model-finetune/finetune_weight/best_finetune.pt'), metrics={'metrics/precision(B)': 0.6930394145729896, 'metrics/recall(B)': 0.4259259259259259, 'metrics/mAP50(B)': 0.5087361111111111, 'metrics/mAP50-95(B)': 0.26677821340388, 'fitness': 0.26677821340388}, log_path=WindowsPath('D:/7th_sem/Software Design Project/transformer-maintenance-system/tms-model-finetune/logs/finetune_20251021T182808Z.log'), dataset_size=1, feedback_samples=1, replay_samples=0, hyperparams={'epochs': 2, 'batch': 4, 'imgsz': 640, 'lr0': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.937, 'freeze': 10, 'seed': 1337, 'device': 'cpu', 'train_replay': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kick off the fine-tuning run (may take a few minutes depending on hardware)\n",
    "summary = run_finetune(request_payload)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f8708",
   "metadata": {},
   "source": [
    "# Run Evaluation and Sanity Checks\n",
    "Inspect the reported metrics and perform quick assertions so we can spot regressions early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d065614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metrics/precision(B)\": 0.6930394145729896,\n",
      "  \"metrics/recall(B)\": 0.4259259259259259,\n",
      "  \"metrics/mAP50(B)\": 0.5087361111111111,\n",
      "  \"metrics/mAP50-95(B)\": 0.26677821340388,\n",
      "  \"fitness\": 0.26677821340388\n",
      "}\n",
      "Metrics captured for finetune_20251021T182808Z\n"
     ]
    }
   ],
   "source": [
    "# Display metrics and assert they were produced\n",
    "print(json.dumps(summary.metrics, indent=2))\n",
    "assert summary.metrics, \"No metrics returned by fine-tune run\"\n",
    "print(\"Metrics captured for\", summary.run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca7334",
   "metadata": {},
   "source": [
    "# Persist Artifacts and Logs\n",
    "Verify that the fine-tuned weights and diagnostic artifacts are present in the expected locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e16bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved to: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\finetune_weight\\best_finetune.pt\n",
      "Exists: True\n",
      "Size (MB): 18.29\n",
      "Log file: D:\\7th_sem\\Software Design Project\\transformer-maintenance-system\\tms-model-finetune\\logs\\finetune_20251021T182808Z.log\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Confirm the exported weights and log files exist\n",
    "weights_path = summary.weights_path\n",
    "print(\"Weights saved to:\", weights_path)\n",
    "print(\"Exists:\", weights_path.exists())\n",
    "if weights_path.exists():\n",
    "    print(\"Size (MB):\", round(weights_path.stat().st_size / (1024 * 1024), 2))\n",
    "\n",
    "log_path = summary.log_path\n",
    "print(\"Log file:\", log_path)\n",
    "print(\"Exists:\", log_path.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3bbf9",
   "metadata": {},
   "source": [
    "# Automate Validation in VS Code Test Explorer\n",
    "Trigger the test suite from the notebook so CI-style validation is only one cell away. Skip or adjust the command if no tests exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41700ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pytest from the repository root (adjust markers if needed)\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().resolve()\n",
    "if repo_root.name == \"tms-model-finetune\":\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "result = subprocess.run([sys.executable, \"-m\", \"pytest\", \"-q\"], cwd=repo_root, check=False)\n",
    "print(\"pytest exit code:\", result.returncode)\n",
    "if result.returncode != 0:\n",
    "    print(\"Tests reported failures or were skipped. Inspect output above for details.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
